[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "I am a self employed data scientist/statistician/software engineer. When I’m not working I enjoy bouldering, swimming, cycling and hiking. I live in Bristol.\nYou can contact me by email: david @ mawds.co.uk\nYou can see my full career history on Linkedin, or in my CV, but briefly:"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About me",
    "section": "Experience",
    "text": "Experience\nSelf Employed | tupledata limited | September 2023 - Present\nTravelling | Europe | Summer 2023\nSenior Research Software Engineer | University of Manchester | June 2021 - June 2023\nTechnical Director | Vuzo Ltd | April 2019 - May 2021\nInterim Infrastructure Director | DataHE | Febuary 2019 - March 2019\nResearch Software Engineer | University of Manchester | November 2016 - January 2019\nResearch Assistant -&gt; Senior Research Associate | University of Bristol | September 2013 - January 2015\nAnalyst -&gt; Senior Analyst | Higher Education Funding Council for England | July 2007 to September 2013"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About me",
    "section": "Education",
    "text": "Education\nMSc Medical Statistics | University of Leicester | October 2013 - September 2014\nPhD Department of Physics | University of Bath | October 2003 - January 2007\nMPhys Physics with Computational Physics | University of Sussex | October 1999 to June 2003"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "David Mawdsley’s Blog",
    "section": "",
    "text": "Reverse engineering Janome embroidery cards\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nUbuntu 24.04 upgrade\n\n\n\n\n\n\n\n\n\n\n\nNov 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLocal fuel prices\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTravels\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nAdding epubs to Kobo from my phone\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nNot so smart metering\n\n\n\n\n\n\nPython\n\n\nRaspberry Pi\n\n\n\n\n\n\n\n\n\nMar 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nEasily deploying Shiny apps\n\n\n\n\n\n\nShiny\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 24, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/janome/janome.html",
    "href": "posts/janome/janome.html",
    "title": "Reverse engineering Janome embroidery cards",
    "section": "",
    "text": "I recently went down a bit of a rabbit hole trying to reverse engineer the embroidery cards for a 1990s Janome Memory Craft 8000 sewing machine I bought.\nI’m hoping to be able to write my own designs to a card, but haven’t got that far yet. As it’s rather a long write up, and still a work in progress I’ve put the write up on a separate page."
  },
  {
    "objectID": "posts/ubuntu_reinstall/ubuntu_reinstall.html",
    "href": "posts/ubuntu_reinstall/ubuntu_reinstall.html",
    "title": "Ubuntu 24.04 upgrade",
    "section": "",
    "text": "I recently had to reinstall Ubuntu on my ageing Thinkpad X260, after the upgrade from 22.04 to 24.04 went horribly wrong.\nI’m still not quite sure what went wrong. It think I’d somehow ended up with (only) the 22.04 kernel installed, which led to lots of “Unknown symbol” errors. My system was quite heavily customised, so it was perhaps a bit optimistic to expect the upgrade to work.\nThis post is mostly a note to self about how I reconfigured the dual boot setup in case I need to do it again (which I hope I don’t).\nI initially thought it was only the kernel that was the problem. This stackexchange post was really useful for mounting the encrypted drive, setting up a chroot environment and reinstalling the kernel. That got me booting to the command prompt.\nIt turned out I was missing most packages, at which point I decided to wipe and restore from backups.\n(I could actually access my encrypted drive through the Ubuntu LiveCDUSB, so took a fresh backup of /home and /etc from this)\nI’d got an (essentially unused and tiny) Windows 10 partition dual booting with Ubuntu. I was keen to keep Windows 10 on the machine, as it’s occasionally useful. I’d previously set this up to dual boot with full disk encryption for both OSs roughly following the guide here, but using the legacy BIOS, as that’s what Windows 10 had come preinstalled with.\nI was pleased to see that the guide had been updated for Ubuntu 24.04 and is now much easier. I took this opportunity to wipe the Windows partition and switch to UEFI too.\nThe basic process was:\n\nUse Ubuntu 24.04 USB image to check backups are OK and work\nUse the Ubuntu USB image and gparted to remove all partitions\nReboot and set the BIOS to UEFI mode (only) (Startup menu in BIOS), and check the security chip is set to “Intel PTT”.\nInstall Windows 10 Pro from installation USB (avoiding creating a Microsoft account by selecting “Work or school account” then “Domain join instead” via\nInstall interminable updates and reboot lots of times (I kept force checking for updates until there were no more). (Bitlocker is not enabled at this point)\nReboot with the Ubuntu USB image\nFollow the instructions at https://www.mikekasberg.com/blog/2024/05/20/dual-boot-ubuntu-24-04-and-windows-with-encryption.html to setup the dual boot with an encrypted partition setup.\nCheck both still boot\nEnable bitlocker on the Windows partition You need to boot Windows via the BIOS’s boot menu (F12 on my machine), not via Grub, otherwise it will prompt you for the bitlocker recovery key on boot (details of how I removed the Windows option from Grub below)\n\nOnce everything was working, I rebooted using the USB image to mount my nfs share containing the backups and restored my data.\nA few post install tweaks:\nHibernate doesn’t work out of the box. I enabled this following the guide on Elbrar’s corner. This requires booting with the USB image again, to resize volumes to make space for the encrypted swap partition (with hindsight, the resizing would probably have been quicker if I did this before restoring my data; even so, it was only a few minutes). I didn’t follow the “Install Clevis” section, as I prefer to enter the decryption key before the machine boots. I used the Hibernate Status Button extension to enable the hibernate menu option on the desktop.\nSuspend didn’t work properly. The system would suspend, but not wake up. I eventually solved this via this Stackexchange post. You need to add intel_iommu=off to the GRUB_CMDLINE_LINUX_DEFAULT options in /etc/default/grub and then update-grub.\nI also took this opportunity to add DISABLE_OS_PROBER=true to the file, so we don’t have the option to boot to Windows from grub, which causes issues with Bitlocker, as mentioned above.\nI also had to force an update of the installed Snaps so that Firefox was at the same version as on the 20.04 system, so that it would load my profile data. Presumably this would’ve happend automatically at some point anyway."
  },
  {
    "objectID": "posts/powermon/powermon.html",
    "href": "posts/powermon/powermon.html",
    "title": "Not so smart metering",
    "section": "",
    "text": "This project has been a while in the making, and I’ve finally got round to finishing it off (well as much as anything is finished). A big part of the delay was, somewhat ireonically, not having a power socket near the meters.\nI’m not a huge fan of Smart Meters - being able to be cut off remotely doesn’t seem a selling point, but I was curious how much energy I was using. I built a circuit with the Raspberry Pi to keep track of much gas and electricity I was using - this uses the GPIO pins to count the flashes on the electricity meter, using an LDR, and to count the rotations of the gas meter using a Hall probe (it turns out the 0 has a magnet in it, which can be detected as it rotates).\nThe measurements are much more precise for the electic meter - there are 1000 flashes per kWh, compared to ~9 per kWh for the gas meter.\nI was originally simply dumping the timestamps (and time difference between successive ones for each power source) into a CSV file, and looking at this in R.\nI wanted to make something where I could see at a glance how much energy I’d been using. I had an old Nook E-Reader, which I planed to use as a display. This blog post was very useful in figuring out how to do this.\ntldr; it runs Android 2.x, the apks linked to on that page were sideloaded via adb, so no need to set up a Google Account. The plan was to use Electic Sign to display a web page containing the current power usage.\n\n\nI’ve now switched to dumping the timestamps to a sqllite database, and am using FastAPI to generate an endpoint that I can display on the Nook:\n\n\n\n\nI plan to move the logging over to a “proper” database. Handling timestamps in Sqllite is a little fiddly. Doing some visualisation of the data is also on the list.\nCode is here"
  },
  {
    "objectID": "posts/powermon/powermon.html#sqllite-and-fastapi",
    "href": "posts/powermon/powermon.html#sqllite-and-fastapi",
    "title": "Not so smart metering",
    "section": "",
    "text": "I’ve now switched to dumping the timestamps to a sqllite database, and am using FastAPI to generate an endpoint that I can display on the Nook:"
  },
  {
    "objectID": "posts/powermon/powermon.html#futher-work",
    "href": "posts/powermon/powermon.html#futher-work",
    "title": "Not so smart metering",
    "section": "",
    "text": "I plan to move the logging over to a “proper” database. Handling timestamps in Sqllite is a little fiddly. Doing some visualisation of the data is also on the list.\nCode is here"
  },
  {
    "objectID": "posts/travels/travels.html",
    "href": "posts/travels/travels.html",
    "title": "Travels",
    "section": "",
    "text": "I’m taking a few months career break to go travelling, which I plan to blog (hopefully more regularly than I manage here!) at https://travel.mawds.co.uk/index.php/europe-2023/. This is running on Wordpress, which is a lot easier to update on a phone than this Quarto based site."
  },
  {
    "objectID": "posts/fuelprice/fuelprice.html",
    "href": "posts/fuelprice/fuelprice.html",
    "title": "Local fuel prices",
    "section": "",
    "text": "I’ve recently launched a new site localfuelprices.co.uk to display the cost of petrol and diesel nearby petrol stations.\nIt’s built using django and geodjango, with leaflet for the mapping."
  },
  {
    "objectID": "posts/shinysender/shinysender.html",
    "href": "posts/shinysender/shinysender.html",
    "title": "Easily deploying Shiny apps",
    "section": "",
    "text": "I’m currently running a pilot Shiny web hosting service at the University of Manchester. One issue with the standalone (free) Shiny Server is that it’s not particularly easy to deploy apps to it. Essentially you have to copy them to the server (e.g. using scp), and sort out any library dependency issues. RStudio’s Posit’s commercial offerings, like RStudio Posit Connect make this process much easier, but are more expensive1.\nTo fill this gap, I wrote an R Package to simplify the deployment of apps to a standalone, open source Shiny Server: Shinysender\n\n\nI designed the package to be as simple to use as possible, to minimise the amount of support required.\nThe server being deployed to is set up in the usual way. A few R packages (shiny, rmarkdown, packrat and devtools) need to be installed for all users, and the server needs to be configured to serve apps from users’ home directories. It’s also sensible to pre-install the “dev” versions of of system libraries that are required by common R packages (e.g. libssl-dev, libxml2-dev etc.; the full list of the ones I’ve used is in the README)\nFull details are provided in the package’s readme. Users need an account on the server to be able to deploy to it.\n\n\n\nThe package isn’t (yet) on CRAN, so it needs to be installed from github:\n\ninstall.packages(\"devtools\")  # If you don't already have devtools installed\ndevtools::install_github(\"UoMResearchIT/r-shinysender\")\n\nThe server and username are determined by the SHINYSENDER_SERVER and SHINYSENDER_USER environment variables. These can be set from the R console, or by adding them to ~/.Rprofile/~/.Renviron:\n\nSys.setenv(SHINYSENDER_SERVER=\"myshinyserver.mawds.co.uk\")  \nSys.setenv(SHINYSENDER_USER=\"david\")\n\nThe “upload app” addin will appear in RStudio, and will deploy the current app to http://myshinyserver.mawds.co.uk/username/appname The user is prompted for their password on the server (an ssh key will be used if available).\nThe user’s environment is replicated as closely as possible using Packrat.\nThere are various options to allow the user to set the name of the app on the server, etc. These are detailed in the readme.\n\n\n\nWe use the ssh library to drive the remote session.\nThe app deployment process checks that the users ShinyApps directory exists and creates it if required. We also create as ShinyApps_staging directory.\nWe then use the rsconnect library to prepare a “bundle” containing the app’s code and dependencies. The bundle is then uploaded over scp to the staging directory and decompressed\nWe then upload a custom .Rprofile which sets up the cache directory for Packrat (so that a user can share R packages between their apps). This doesn’t actually activate Packrat (see below). We then restore the libraries into the Packrat environment, before swapping the .Rprofile for one that actually activates Packrat when the app is run.\nAssuming everything has worked, we then move the app directory from ShinyApps_staging to ShinyApps, to make it live.\n\n\nOne feature I was keen on implementing was being able to install custom libraries from Github. These might be stored in a private repository. To handle this, we set any local GITHUB_PAT on the remote before we restore the R packages (We do this as a single command, with history turned off, so the PAT is never actually stored on the server2).\nIf we use the same .Rprofile for deployment and staging, we won’t have access to the (system-wide) devtools library, which is required to install packages from github. Hence the need for a staging .Rprofile and a live one.\nI should add that our .Rprofile is appended to any existing .Rprofile, rather than being overwritten, so any settings the user has used will be preserved.\n\n\n\n\nShiny server doesn’t let you use more than one version of R. Although we attempt to replicate the user’s environment as closely as possible, this does mean that they’re stuck with the version of R on the server. In practice, this hasn’t proved an issue so far, but is likely to become problematic when R’s major version increments.\nThe usual limitations of hosting apps on the free version of Shiny server (i.e. an app only has a single process, which is shared by all users applies). On my aspirational todo list is to deploy apps using Shinyproxy - this would mean each app was hosted in its own Docker container. In principle that should be fairly straightforward, since the packrat steps are generic. From a security perspective it’s more difficult, since the shinyproxy config would need to be modified by a privileged user to pick up the new app. Essentially I’d need to write an API for the server to do this, rather than just “driving” a remote ssh session as the user.\nIt’d be better to run the whole thing behind an API, but since the Shiny apps are run as the user, and are deployed using the user account the security risks are much lower. The server is locked down so users cannot see others’ home directories etc."
  },
  {
    "objectID": "posts/shinysender/shinysender.html#usage---server-setup",
    "href": "posts/shinysender/shinysender.html#usage---server-setup",
    "title": "Easily deploying Shiny apps",
    "section": "",
    "text": "I designed the package to be as simple to use as possible, to minimise the amount of support required.\nThe server being deployed to is set up in the usual way. A few R packages (shiny, rmarkdown, packrat and devtools) need to be installed for all users, and the server needs to be configured to serve apps from users’ home directories. It’s also sensible to pre-install the “dev” versions of of system libraries that are required by common R packages (e.g. libssl-dev, libxml2-dev etc.; the full list of the ones I’ve used is in the README)\nFull details are provided in the package’s readme. Users need an account on the server to be able to deploy to it."
  },
  {
    "objectID": "posts/shinysender/shinysender.html#usage---app-deployment",
    "href": "posts/shinysender/shinysender.html#usage---app-deployment",
    "title": "Easily deploying Shiny apps",
    "section": "",
    "text": "The package isn’t (yet) on CRAN, so it needs to be installed from github:\n\ninstall.packages(\"devtools\")  # If you don't already have devtools installed\ndevtools::install_github(\"UoMResearchIT/r-shinysender\")\n\nThe server and username are determined by the SHINYSENDER_SERVER and SHINYSENDER_USER environment variables. These can be set from the R console, or by adding them to ~/.Rprofile/~/.Renviron:\n\nSys.setenv(SHINYSENDER_SERVER=\"myshinyserver.mawds.co.uk\")  \nSys.setenv(SHINYSENDER_USER=\"david\")\n\nThe “upload app” addin will appear in RStudio, and will deploy the current app to http://myshinyserver.mawds.co.uk/username/appname The user is prompted for their password on the server (an ssh key will be used if available).\nThe user’s environment is replicated as closely as possible using Packrat.\nThere are various options to allow the user to set the name of the app on the server, etc. These are detailed in the readme."
  },
  {
    "objectID": "posts/shinysender/shinysender.html#how-it-works",
    "href": "posts/shinysender/shinysender.html#how-it-works",
    "title": "Easily deploying Shiny apps",
    "section": "",
    "text": "We use the ssh library to drive the remote session.\nThe app deployment process checks that the users ShinyApps directory exists and creates it if required. We also create as ShinyApps_staging directory.\nWe then use the rsconnect library to prepare a “bundle” containing the app’s code and dependencies. The bundle is then uploaded over scp to the staging directory and decompressed\nWe then upload a custom .Rprofile which sets up the cache directory for Packrat (so that a user can share R packages between their apps). This doesn’t actually activate Packrat (see below). We then restore the libraries into the Packrat environment, before swapping the .Rprofile for one that actually activates Packrat when the app is run.\nAssuming everything has worked, we then move the app directory from ShinyApps_staging to ShinyApps, to make it live.\n\n\nOne feature I was keen on implementing was being able to install custom libraries from Github. These might be stored in a private repository. To handle this, we set any local GITHUB_PAT on the remote before we restore the R packages (We do this as a single command, with history turned off, so the PAT is never actually stored on the server2).\nIf we use the same .Rprofile for deployment and staging, we won’t have access to the (system-wide) devtools library, which is required to install packages from github. Hence the need for a staging .Rprofile and a live one.\nI should add that our .Rprofile is appended to any existing .Rprofile, rather than being overwritten, so any settings the user has used will be preserved."
  },
  {
    "objectID": "posts/shinysender/shinysender.html#limitations",
    "href": "posts/shinysender/shinysender.html#limitations",
    "title": "Easily deploying Shiny apps",
    "section": "",
    "text": "Shiny server doesn’t let you use more than one version of R. Although we attempt to replicate the user’s environment as closely as possible, this does mean that they’re stuck with the version of R on the server. In practice, this hasn’t proved an issue so far, but is likely to become problematic when R’s major version increments.\nThe usual limitations of hosting apps on the free version of Shiny server (i.e. an app only has a single process, which is shared by all users applies). On my aspirational todo list is to deploy apps using Shinyproxy - this would mean each app was hosted in its own Docker container. In principle that should be fairly straightforward, since the packrat steps are generic. From a security perspective it’s more difficult, since the shinyproxy config would need to be modified by a privileged user to pick up the new app. Essentially I’d need to write an API for the server to do this, rather than just “driving” a remote ssh session as the user.\nIt’d be better to run the whole thing behind an API, but since the Shiny apps are run as the user, and are deployed using the user account the security risks are much lower. The server is locked down so users cannot see others’ home directories etc."
  },
  {
    "objectID": "posts/shinysender/shinysender.html#footnotes",
    "href": "posts/shinysender/shinysender.html#footnotes",
    "title": "Easily deploying Shiny apps",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThey also offer other features, like making the app more scalable if it has many concurrent users.↩︎\nThis was the most secure way I could think of doing this..if there are better ways I’d be grateful to hear of them.↩︎"
  },
  {
    "objectID": "posts/kobo/kobo.html",
    "href": "posts/kobo/kobo.html",
    "title": "Adding epubs to Kobo from my phone",
    "section": "",
    "text": "I’ve got a Kobo e-reader, which is very fussy about the USB cable used to copy books to it (and even the USB port the cable is connected to). I want to be able to sideload books from, e.g. Project Gutenberg to it from my phone. The (beta) web browser that’s included with the Kobo is very basic, and I’ve struggled to get it to work with most web sites, so the obvious solution doesn’t really work.\nWith thanks to this post, I figured out a way to do this.\nEssentially you download your books using Chrome on the phone, and then use termux, which give a Linux-like environment on the phone, to run a minimal web-server whose output works with the Kobo’s browser."
  },
  {
    "objectID": "posts/kobo/kobo.html#setup",
    "href": "posts/kobo/kobo.html#setup",
    "title": "Adding epubs to Kobo from my phone",
    "section": "Setup",
    "text": "Setup\nAt the termux prompt: (this only needs to be done once)\ntermux-setup-storage # Gives access to the Download folder on android \npkg install python3 # Install Python"
  },
  {
    "objectID": "posts/kobo/kobo.html#to-use",
    "href": "posts/kobo/kobo.html#to-use",
    "title": "Adding epubs to Kobo from my phone",
    "section": "To use",
    "text": "To use\nEnable tethering on the phone (I also found I had to disable the VPN running on the phone)\nAt the termux prompt:\nifconfig # Note the ip associated with wlan0\ncd ~/storage/downloads # Assuming this is where the book is\npython -m http.server 8080\nOn the Kobo, connect to the phone’s hotspot, open the browser (more, beta features), and navigate to http://&lt;phone’s ip&gt;:8080 This gives a very basic directory listing, which works OK on the Kobo"
  },
  {
    "objectID": "janome/janome.html",
    "href": "janome/janome.html",
    "title": "Reverse engineering Janome embroidery cards",
    "section": "",
    "text": "I recently bought a Janome Memory Craft 8000 from eBay for a sewing project. The machine dates from the early 90s, but was top-of-the-range when it was released. It was also (one of?) the first machines to embroider designs off a memory card. I’ve used it for sewing quite successfully, but have ended up going down a rabbit hole with its embroidery features….\nThe vendor was also selling a “Scan n Sew” unit. This is a standalone device that consists of a monochrome hand scanner integrated with a roughly laptop sized box. The device allows you to scan a design and automatically convert it to an embroidery file, which is written to a special memory card.\nI’ve been trying to figure out the format of the data on the memory cards, with a view to writing my own designs to a custom card (TLDR - I’ve not got that far).\nThe pyembroidery library, which is used by InkStitch can read the .sew files which (I thought) my machine used, and write .jef files (which is the format used by newer Janome machines, which has some similarities with .sew files).\nI found an (abandoned?) attempt at reading the cards of the newer 9000 model on hackaday (these cards are 512kb capacity, mine are 128kb; I don’t know whether the format of the designs is different, or if they’re just larger capacity)."
  },
  {
    "objectID": "janome/janome.html#getting-data-off-the-cards",
    "href": "janome/janome.html#getting-data-off-the-cards",
    "title": "Reverse engineering Janome embroidery cards",
    "section": "Getting data off the cards",
    "text": "Getting data off the cards\n\nPhysical format\nThe machine came with a single (read only card), which contains the alphabet in various fonts for embroidering words. When new the machine would’ve come with an additional card containing designs, but I didn’t get this. Various cards come up for sale on eBay containing different designs. I’ve bought a few of these, including the design card that would’ve come with the machine.\nThe cards look like PCMCIA cards, except they have only a single row of 34 connectors, vs 2x34 on a PCMCIA card. The Scan n Sew card has the same form factor, but also contains a button cell battery to maintain the memory. This card has (according to the label) a 32 kb rom and 96 kb ram(!). The Scan n Sew allows you to store 4 designs, each of up to 4 colours. This contrasts with the ROM cards, which have more designs and more colours per design.\n\n\n\nCard top view\n\n\n\n\n\nCard connector view\n\n\nSome searching for 34 pin memory eventually led me to the retrocomputing forum where someone provided a potential pin-out for a similar looking card, albeit with a lower capacity.\nThe Scan N Sew contains a D70320GJ-8 microcontroller. Checking the continuity from its address and data lines to the connector in the scan n sew confirmed the pin assignments were correct, and gave me the pins for the A15 and A16 lines (A17 was also connected on the scan n sew, but isn’t used - perhaps a larger capacity card was planned)\n\n\n\n\n\n\nConnector pinout\n\n\n\n\n\n\n5V\nA14\nA12\nEC??\nA7\nA13\nNC\nNC\nA6\nA8\nA5\nA9\nA4\nA11\nA3\nOE(?)\nA2\nA10\nA1\n?CS??\nA17\nA15\nA16\nA0\nD7\nD0\nD6\nD1\nD5\nD2\nD4\nD3\nGND\nGND\n\n\n\n\n\n\nExtracting the data\nI planned to try and read the data off the card by wiring up an old PCMCIA connector (lightly modified with a hacksaw). Looking at the connector on the machine, it looks like the pins are offset from the centre, so I was hoping that this would work. After much soldering I concluded that the pins weren’t making contact, so gave up on that approach. (With hindsight I should’ve just soldered the two ground pins and checked for continuity between them via the card)\n\n\n\nPCMCIA connector\n\n\nI then decided to solder directly to the back of the connector on a dismantled card. I should’ve used thinner wire :-(\n\n\n\nSoldered connector\n\n\n\n\nReading the data\nA link on the PES2Card site helpfully listed the chip numbers in each of the after market cards. These are all 29F040B. Searching for this led me to a post on the Arduino forum, to make a programmable cartridge for a gameboy.\nUsing some of the code from this thread, and the repo for the OP’s code, I built a circuit using a couple of shift 8 bit shift registers (plus an additional GPIO line for A16) to read the data from the card.\nThis was getting something off the card, but the start of the card appeared to be blank (this turned out to be correct), and I eventually realised some areas were repeated. This led me to suspect a short on a couple of the address lines.\nI then learned that these exist. This simplified things greatly(!)\nWiring up the Arduino with the clip, I was able to figure out the pinout for the ROM, and get a dump of it.\n\n\n\n\n\n\nChip pinout\n\n\n\n\n\n\n\n\npin\npin\n\n\n\n\n1. A15\n28. +5v\n\n\n2. A12\n27. A14\n\n\n3. A7\n26. A13\n\n\n4. A6\n25. A8\n\n\n5. A5\n24. A9\n\n\n6. A4\n23. A11\n\n\n7. A3\n22. A16\n\n\n8. A2\n21. A10\n\n\n9. A1\n20. CS(?)\n\n\n10. A0\n19. D7\n\n\n11. D0\n18. D6\n\n\n12. D1\n17. D5\n\n\n13. D2\n16. D4\n\n\n14. GND\n15. D3"
  },
  {
    "objectID": "janome/janome.html#decoding-the-rom",
    "href": "janome/janome.html#decoding-the-rom",
    "title": "Reverse engineering Janome embroidery cards",
    "section": "Decoding the ROM",
    "text": "Decoding the ROM\nThe research I’d done suggested that early Janome machines use the SEW file format, which was succeeded by their JEF format. The pyembroidery library has a reader for both of these file types. I could find out little beyond that about the format, beyond the source code for pyembroidery’s reader until I found a page for an (abandoned?) KDE embroidery project which had some information on the specification of both file types.\nI was expecting to find chunks of memory each containing a sew file, and some sort of FAT to point the machine to the start address of each design. Sadly this proved not to be the case.\nThe first 0x2000 of all the cards I read is blank. I tried reading the dump in as a sew file using pyembroidery. Trying a few promising looking offsets gave me something that looked like a part of a design.\nThis means we know the stitch data is stored in the same format as the sew files (2s complement. 1 byte for x, 1 byte for y, 2 byte control characters, for, e.g. move.) I worked out that we need to start on an even byte otherwise design goes wrong on a control character.\nI then looked at what we got if we treat everything as a stitch in the entire dump, to try and figure out how the data are arranged. This is shown below. (this doesn’t display properly on mobile)\n\n\n                        \n                                            \n\n\nThe stitch data is quite hard to see amongst all the other stuff on the card. It’s highlighted in red on the (zoomable) plot above. One lot of stitch data is in the bottom 64k of the chip, the other in the upper.\nThere’s a separate set of stitches for each colour in each design, but no obvious delimiter between designs and colours (the stuff between designs corresponds to move commands to move the needle to the right place to start the next colour. As the biggest move is 12.7mm multiple moves are sometimes needed to get to the right place).\n\nAn Easter egg\nI noticed what I thought was an Easter egg in the data, at the end of the first bank of stitches:\n\n\n                        \n                                            \n\n\nUnfortunately looking at the other bank of stitches, and data on other cards showed that there was often “junk” at the end of the stitch data (and elsewhere on the cards). Presumably whatever method was used to make the cards didn’t wipe the image used by the previous card, leading to these “ghosts”\n\n\nFinding a FAT\nI located the start address of each colour per pattern (“chunk”), and looked for these addresses elsewhere on the card. I located these addresses at 0xFA00 (and 0x1FA00), stored little endian. The addresses in the upper memory bank just use 0x10000 as a mask. There were also some “dummy” values in this area, that didn’t correspond to a memory address. I identified more likely addresses at 0XFC00 (and 0x1FC00). These appear correspond to the end address of each chunk of stitches\nI read these in pairwise (i.e. 0xFA00 and 0xFC00, 0xFA02 and 0xFC02), and kept the chunk if both start and end addresses are plausible (e.g. different, neither is FF FF etc). This isn’t perfect; there a few false positives, but it mostly works to identify the chunks of stitches referred to on the card (and removes the Easter eggs/ghost chunks)\nThese can be read as a pattern using a lightly modified version of the SEW reader in Pyembroidery, which allows them to be saved as an svg (or any of the other embroidery formats pyembroidery supports).\nThis doesn’t, however, allow us to distinguish between the patterns on a card, or to establish what colour is associated with each chunk.\n\n\n\nDesigns from the card\n\n\nOr, by working out which chunk belongs to each pattern, just extract a single pattern:\n\n\n\nA single design\n\n\n\n\nThe other stuff on the card\n\nBitmaps\nThe sew file format, which I’d naively assumed the machine used, contains bitmaps of the pattern in various resolutions (presumably for the machine to display as a preview). I looked for bitmaps on other parts of the card to see whether these existed elsewhere on the card.\nThere are bitmaps containing the overall design and previews for each colour on the card (and the names of the colours as bitmaps). The former are 4 bytes wide (1 bit/pixel), the latter are 3 bytes wide:\n\n\n                        \n                                            \n\n\n\n\n                        \n                                            \n\n\nThere are also images for the touch-screen’s icons:\n\n\n                        \n                                            \n\n\nAnd some text in Japanese:\n\n\n                        \n                                            \n\n\nI assume this is ghost data from a different card (translating it in Google Translate suggests it’s instructions for an applique, where you cut out the design and stick it on another piece of fabric)\nThe offsets for the various image types vary by card, but seem to be in similar places.\n\n\nDevice firmware?\nI compared the rom dumps of several of the cards in a hex editor. All have the following features:\n\nNothing until 0x2000\nSome sort of lookup just after this: \n\nGiven the touchscreen button bitmaps are included on the ROM, I’m assuming some of the remaining data is firmware to drive the machine.\nI’ve not got much further than this. 0x12978 seems to have the number of colours in each design."
  },
  {
    "objectID": "janome/janome.html#writing-data",
    "href": "janome/janome.html#writing-data",
    "title": "Reverse engineering Janome embroidery cards",
    "section": "Writing data",
    "text": "Writing data\nI’m fairly happy I could modify the gameboy write code to write an image to a suitable chip, such as the 29F010B.\nI’ve successfully found the start and end addresses of each chunk, it should be possible to overwrite bits of an existing ROM image with the new stitches, and update the addresses to the new regions (and optionally update the icon bitmaps for the design). The new design would need to have the same or fewer colours than the design being overwritten, as I’ve not yet figured out how to link each chunk to a design. In principle, this should allow custom designs to be written, using a modified version of PyEmbroidery’s JEF writer functionality (the part containing the stitches is basically the same).\nI’ve held off trying to get any further than this until I find a way of making a homebrew card."
  },
  {
    "objectID": "janome/janome.html#making-a-new-card",
    "href": "janome/janome.html#making-a-new-card",
    "title": "Reverse engineering Janome embroidery cards",
    "section": "Making a new card",
    "text": "Making a new card\nI’m really not sure how to start with this :-( The card connector obsolete. I’m not sure whether it was ever used on anything besides these machines. This was presumably also an issue for the people behind the Echidna converter: “you need to supply us an exchange memory card to suit the Memory Craft 8000. This card can be any MC8000 card that you already own.For example you may have a card that you don™t like or are never likely to use.”\nIt might be possible to modify a PCMCIA card (PCMCIA to CF adaptor? But those are a little thicker). The pins on the machine should be longer, given the ones on the PCMCIA socket were too short. I’ve not tried this yet, as I’m reluctant to risk damaging the connector inside the machine. It’s very fiddly to solder the 0.05” connectors.\nOne approach might be to sacrifice an existing card and connect wires from its connector to a breadboard containing a flash chip. This could be programmed via a clip.\n\nUpdate 9 April 2025\nI found some connectors on AliExpress that I thought might work, having the correct spacing (1.27mm).\nI made a FreeCAD model of the card, which I 3d printed. I cut the connector down to 34 pins and glued it into the card. Unfortunately this couldn’t be inserted into the machine’s socket. I suspect the pins in the machine are wider than the connectors’ holes.\n I’ve been unable to find a connector that more closely matches the original.\nFeel free to get in touch if you’ve any suggestions.\n\n\nCode\nThe sketch to read a ROM is at https://github.com/mawds/read_mc8000_rom/\nThe code I developed to look at the ROM, building on pyembroidery is in the mc8000 branch of my fork of their repository: https://github.com/mawds/pyembroidery/tree/mc8000 This defines a JanomeCard class which allows you to read the stitch offsets from a card dump, output (selected) chunks, etc. It’s very much a work in progress.\n\n\nAcknowlegements\nThanks to Roger for the encouragement!"
  }
]